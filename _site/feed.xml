<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Saahil's Tech and Personal Space</title>
    <description>On this website, I write my thoughts, tasks and everything that doesn't belong anywhere else.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>The Rift Between Open-source and Commercial Software Is Not Irreconcilable</title>
        <description>&lt;p&gt;The most notable thing that makes the development of commercial software and FOSS different is the culture of being product focused vs. one of sharing.&lt;/p&gt;

&lt;p&gt;“What can we engineer that makes us the most money and sustain?” vs. “I love this thing I made, I’m sure there’s someone out there that finds it cool”.&lt;/p&gt;

&lt;p&gt;I’m probably being unfair with the “makes money” part (disclosure: I work on commercial software all day), but you get my drift - feel free to replace it with “gets the most users to stay” or “gets the most word out” etc.&lt;/p&gt;

&lt;p&gt;However, all that is not to say that one culture of development is better than the other, but I do think that acknowledging the difference is important for developers and aligned personas to appreciate different motivations better. While the former leads to coherent product experiences, the latter leads to crazy (good) experiments, creative masterworks and worthwhile alternatives to drab experiences.&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Nov 2022 08:00:00 +0100</pubDate>
        <link>http://localhost:4000/technology/software/open-source/product/2022/11/07/open-source-vs-commercial/</link>
        <guid isPermaLink="true">http://localhost:4000/technology/software/open-source/product/2022/11/07/open-source-vs-commercial/</guid>
      </item>
    
      <item>
        <title>Data Quality Metrics for Everybody</title>
        <description>&lt;p&gt;Training the first ML model in a business app is usually driven by extensive experimentation, exploration and, what is essentially, making a lot of reasonable assumptions about what a future user’s characteristics are and how they will behave. At inference time, however, nobody should be surprised when these assumptions are violated by reality left, right and centre, and you’re left with some pretty tricky scenarios to diagnose and debug. As a starting point for these investigations, which should, ideally, involve feature importances, explanations, and so on, should be a good grip on whether the latest training data, as well as inference-time input meets a basic set of quality measures.&lt;/p&gt;

&lt;p&gt;This article won’t go into any business use-case specific assumptions, obviously, but the following are the bare minimum in terms of data quality metrics that you should put in place, and automate, at the end of your ETL pipelines and inference endpoints.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;Null values&lt;/em&gt;: Whether there are missing values in fields where there shouldn’t be any.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Casting of values&lt;/em&gt;: Whether the input data flows in in a format that your casting operations can’t handle, e.g. string “1.0” can be cast into floating point, but “1 point something” cannot be.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Fill rates&lt;/em&gt;: For sparse feature matrices, an overview of column fill rates is important, especially how it has evolved over the time since your model was last trained.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Timeliness&lt;/em&gt;: If models are trained periodically upon availability of new ground-truth data, then a timeliness check is what allows data scientist to track whether &lt;em&gt;all the expected data&lt;/em&gt; was updated, and to what degree, at the expected intervals.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Historical consistency&lt;/em&gt;: As a final check, historical consistency should give an indication of whether any &lt;em&gt;qualitative&lt;/em&gt; aspects of the data have changed over time, e.g. has a numerical field always been delivering integer values or have the sources been recently delivering floating point values instead - denoting certain new assumptions about the data.&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 17 Aug 2022 09:00:00 +0200</pubDate>
        <link>http://localhost:4000/data/technology/ai/2022/08/17/data-quality/</link>
        <guid isPermaLink="true">http://localhost:4000/data/technology/ai/2022/08/17/data-quality/</guid>
      </item>
    
      <item>
        <title>The AI of Your ML Products Can Also be an Attack Surface</title>
        <description>&lt;p&gt;Even though non-ML fields in computer science are swiftly turning into auxiliary and domain-specific machine learning research fields (e.g. look at the number of papers using or addressing machine learning in this year’s &lt;a href=&quot;https://conf.researchr.org/program/icse-2022/program-icse-2022/Detailed-Table&quot;&gt;International Conference for Software Engineering&lt;/a&gt;), the core research in ML and deep learning moves so fast, that it’s impossible these days for researchers from other fields to keep track of all the new developments.
Serious researchers, however, have &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/9252851&quot;&gt;already&lt;/a&gt; &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/8474192&quot;&gt;started&lt;/a&gt; &lt;a href=&quot;https://ieeexplore.ieee.org/abstract/document/8617013&quot;&gt;to look&lt;/a&gt; into an important, but often overlooked aspect due to the speed of new developments, in machine learning systems - &lt;em&gt;security&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Security, in this article, is probably a catch-all for a lot of related but, theoretically speaking, distinct concepts such as robustness, safety, and adversarial-proof machine learning systems. If we use the &lt;a href=&quot;https://arxiv.org/abs/1806.00098&quot;&gt;artifact-based approach&lt;/a&gt; to software engineering, security for machine learning systems should focus on these main artifacts -&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Training data&lt;/li&gt;
  &lt;li&gt;Trained models&lt;/li&gt;
  &lt;li&gt;Inference endpoints or APIs&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Training data&lt;/strong&gt;, especially when sourced from ELT pipelines and automatically labeled, can be the first source of poisoning if, either meaningful data quality metrics are not set-up and visible (more on this in a later post), or if active-learning is set up where adversarial edge-case inputs are added to the training datasets without correcting the labels first.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Trained models&lt;/strong&gt; can further add to the attack surface of an ML-system when it is not updated over the course of business use-case serving, and they &lt;em&gt;drift&lt;/em&gt; due to the initial assumptions about the independent variables or problem statements not being valid anymore. Moreover, it can be argued that deep models whose outputs cannot be sufficiently &lt;em&gt;explained&lt;/em&gt;, can be hard to debug and are a compliance and security liability, in themselves.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Inference endpoints&lt;/strong&gt;, typically in the form of Rest or GraphQL APIs, may, in addition to being vulnerable to common software vulnerabilities, also be susceptible to being abused by, e.g. training proxy models by attackers or inferring on adversarial inputs.&lt;/p&gt;
</description>
        <pubDate>Wed, 29 Jun 2022 13:00:00 +0200</pubDate>
        <link>http://localhost:4000/technology/ai/machine-learning/security/deep-learning/2022/06/29/security-in-ml/</link>
        <guid isPermaLink="true">http://localhost:4000/technology/ai/machine-learning/security/deep-learning/2022/06/29/security-in-ml/</guid>
      </item>
    
      <item>
        <title>Who are our Review Meetings for?</title>
        <description>&lt;p&gt;Upcoming&lt;/p&gt;
</description>
        <pubDate>Tue, 22 Mar 2022 08:00:00 +0100</pubDate>
        <link>http://localhost:4000/organization/2022/03/22/review-meetings/</link>
        <guid isPermaLink="true">http://localhost:4000/organization/2022/03/22/review-meetings/</guid>
      </item>
    
      <item>
        <title>Most Data Fabrics are Made Of Lead, not Linen</title>
        <description>&lt;p&gt;Gartner defines Data Fabric as&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;“a design concept that serves as an integrated layer (fabric) of data and connecting processes”&lt;/p&gt;

  &lt;p&gt;– &lt;cite&gt;&lt;a href=&quot;https://www.gartner.com/smarterwithgartner/data-fabric-architecture-is-key-to-modernizing-data-management-and-integration&quot;&gt;Gartner&lt;/a&gt;&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It even places itself as a sibling to the data virtualization idea - that proposes a “logical” data layer on top of disparate sources, where data resides in varying formats. 
While most data fabric providers promise the world at the click of a button, it remains the case that most businesses need to use a semantic engine on top of their original sources, in order to run meaningful data analytics. These semantic engines are what ultimately often plug into an org’s data lake pipelines and feed into the data fabric, that is able to keep the data fresh for quick analytics.&lt;/p&gt;

&lt;p&gt;Creating a domain- or org-specific AI-driven data integration strategy from scratch (and it often &lt;em&gt;need to be&lt;/em&gt; from scratch) sounds frightening, especially given how prolific the development in vector-search space has been recently. For D&amp;amp;A teams, this often means top-down mandates and project charters talking about digital transformation, breaking of department-silos, machine learning capabilities, question-and-answer capabilities yada, yada, yada.&lt;/p&gt;

&lt;p&gt;But I’m here to tell you - you’ve got this. And the reason I say this is because, unlike what the hype tries to make you believe, most data integration layers are built using domain-specific, time-consuming and &lt;em&gt;heavy&lt;/em&gt; transformations to even bring their original sources to a state that they can index it in a Lucene-based text search engine. And while that might not seem impressive if you’re on data management LinkedIn too much, it is enormous when it comes to solving your organization’s specific needs and maybe even create new business models.&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Mar 2022 08:00:00 +0100</pubDate>
        <link>http://localhost:4000/data/technology/ai/2022/03/08/data-fabric/</link>
        <guid isPermaLink="true">http://localhost:4000/data/technology/ai/2022/03/08/data-fabric/</guid>
      </item>
    
      <item>
        <title>Why Aren't Data Behemoths Crushing It Harder?</title>
        <description>&lt;p&gt;While the ten oldest newspapers still in circulation &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_the_oldest_newspapers&quot;&gt;almost exclusively&lt;/a&gt; began in Europe, none of these make it to the list of top newspapers by circulation &lt;a href=&quot;https://en.wikipedia.org/wiki/List_of_newspapers_by_circulation&quot;&gt;today&lt;/a&gt;. An analogous comparison can be made for the oldest banks and insurance companies in the world too - when compared by their total assets or loss ratios, respectively. 
For most industry veterans, it is not for a lack of digitalization schemes that they haven’t been able to conquer modern markets completely, but - and I’m obviously biting off a lot more than I can chew - what that digitalization entails.&lt;/p&gt;

&lt;p&gt;It isn’t enough that historical data is digitalized and suitably archived - what matters much more is whether the data is &lt;em&gt;activated&lt;/em&gt;. 
Activated data is fresh (despite being old), malleable, and &lt;a href=&quot;https://saahil.github.io/technology/philosophy/data/2022/02/10/metaphors&quot;&gt;vocal&lt;/a&gt;.
Activated data knows what it is.&lt;/p&gt;

&lt;p&gt;Semantic web is already a magnificent achievement, in terms of categorizing and standardizing data on the internet. Domain knowledge graphs can even further build upon the semantic web idea to &lt;em&gt;activate&lt;/em&gt; data, and enable organizations to make decisions and generate value.&lt;/p&gt;
</description>
        <pubDate>Tue, 22 Feb 2022 08:00:00 +0100</pubDate>
        <link>http://localhost:4000/technology/data/2022/02/22/digitalization-talking-data/</link>
        <guid isPermaLink="true">http://localhost:4000/technology/data/2022/02/22/digitalization-talking-data/</guid>
      </item>
    
      <item>
        <title>Metaphors in Technology</title>
        <description>&lt;p&gt;Working closely with semantic web technologies every day, a common refrain we hear is “Talk to your data”. Talk TO your data? Kind of like talking to a wall, then? Talking to your data, much like talking to a wall, undoubtedly reflects a desperate and frustrating attempt that, unless &lt;em&gt;data talks back&lt;/em&gt;, is ultimately futile. Hopefully, your data won’t just talk back, but &lt;em&gt;sing&lt;/em&gt;!&lt;/p&gt;

&lt;p&gt;For a discipline whose fundamental building tools are (programming) languages, we, software engineers and statisticians, are notoriously bad at putting metaphors to work - if for nothing else, then to tell better stories with and about (not TO) our products.&lt;/p&gt;
</description>
        <pubDate>Thu, 10 Feb 2022 08:25:00 +0100</pubDate>
        <link>http://localhost:4000/technology/philosophy/data/2022/02/10/metaphors/</link>
        <guid isPermaLink="true">http://localhost:4000/technology/philosophy/data/2022/02/10/metaphors/</guid>
      </item>
    
      <item>
        <title>Innovations and Innovations</title>
        <description>&lt;p&gt;Here’s a interesting paraphrased quote about types of innovation, from a book I’ve been reading this week&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Steam engines increased global productivity by many orders of magnitude…(while)…1970s saw a decline in American national productivity, seemingly reflected in the kind of innovations such as replacing window room air-conditioners with central building air-conditioners.”&lt;/p&gt;

  &lt;p&gt;– &lt;cite&gt;&lt;a href=&quot;https://www.goodreads.com/book/show/23316526-the-second-machine-age&quot;&gt;The Second Machine Age: Work, Progress, and Prosperity in a Time of Brilliant Technologies&lt;/a&gt;, &lt;em&gt;Andrew McAfee and Erik Brynjolfsson&lt;/em&gt; &lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The quote kept me up a while trying to think of similar examples&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“An innovation like eBay, not Facebook”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;“An innovation like lamp shades, not Nest”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;…&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Fri, 04 Feb 2022 09:00:00 +0100</pubDate>
        <link>http://localhost:4000/technology/2022/02/04/innovation-types/</link>
        <guid isPermaLink="true">http://localhost:4000/technology/2022/02/04/innovation-types/</guid>
      </item>
    
  </channel>
</rss>
